======================================================================
ANALYSIS TOOL: Batch 1 (Iters 1-4) - Understanding Difficult Models
======================================================================

=== CONNECTIVITY R² ANALYSIS ===

Model 049: R²=-1.2653 (baseline=0.6340, change=-1.8993) [REGRESSED]
Model 011: R²=-0.9858 (baseline=0.3080, change=-1.2938) [REGRESSED]
Model 041: R²=-0.6982 (baseline=0.6290, change=-1.3272) [REGRESSED]
Model 003: R²=0.6115 (baseline=0.6270, change=-0.0155) [SIMILAR]


=== W_TRUE STRUCTURE COMPARISON ===
Looking for structural differences that explain model difficulty...

Model    Nonzero%   Mean         Std          |W|<0.01%    |W|>0.1%     SVD_rank99  
--------------------------------------------------------------------------------
049      97.23      0.012590     0.290802     33.6         16.1         19          
011      95.88      0.003874     0.309673     39.2         15.9         45          
041      98.42      0.012930     0.330953     35.1         17.9         6           
003      95.67      0.006927     0.271014     35.9         18.4         60          


=== MODEL 049 REGRESSION INVESTIGATION ===
Why did data_aug=25 cause regression from 0.634 to 0.141?

W_learned statistics:
  Mean: -0.017019 (true: 0.012590)
  Std:  0.260268 (true: 0.290802)
  Min:  -3.085261 (true: -5.251400)
  Max:  3.929298 (true: 2.262594)
  Variance ratio (learned/true): 0.8010
  Pearson correlation: -0.2536

Error by weight magnitude:
  |W|<0.01: n= 145905, mean_error=+0.006301, std_error=0.106504
  0.01≤|W|<0.1: n= 218525, mean_error=-0.031925, std_error=0.196031
  |W|≥0.1: n=  69682, mean_error=-0.097538, std_error=1.018024


=== V_REST COLLAPSE INVESTIGATION ===
Why do Models 011/041 have V_rest collapse while 003 doesn't?

Model 049:
  V_rest_true: mean=0.3033, std=0.5837, range=[-1.0087, 2.6330]
  Embeddings: shape=(13741, 2), mean=0.9455, std=0.8236
  Embedding dim 0: mean=0.8312, std=0.7457
  Embedding dim 1: mean=1.0599, std=0.8799

Model 011:
  V_rest_true: mean=0.3733, std=0.4803, range=[-0.8732, 1.9259]
  Embeddings: shape=(13741, 2), mean=0.6222, std=0.8984
  Embedding dim 0: mean=0.5743, std=0.9510
  Embedding dim 1: mean=0.6701, std=0.8396

Model 041:
  V_rest_true: mean=0.3886, std=0.4616, range=[-0.9170, 2.1728]
  Embeddings: shape=(13741, 2), mean=1.3272, std=1.3079
  Embedding dim 0: mean=1.4337, std=1.2613
  Embedding dim 1: mean=1.2207, std=1.3445

Model 003:
  V_rest_true: mean=0.4205, std=0.4262, range=[-0.6497, 2.0920]
  Embeddings: shape=(13741, 2), mean=0.8737, std=0.8409
  Embedding dim 0: mean=0.8797, std=0.7380
  Embedding dim 1: mean=0.8678, std=0.9324


=== SVD ANALYSIS OF W_TRUE ===
Examining spectral structure of connectivity matrices...

Model 049:
  Top 5 singular values: [10.64667746 10.64461024 10.64265457 10.64072592 10.6393681 ]
  SVD rank at 90% var: 90
  SVD rank at 99% var: 99
  Condition number (s[0]/s[k-1]): 1.00

Model 011:
  Top 5 singular values: [10.05124999 10.04987272 10.04854268 10.04720508 10.04620642]
  SVD rank at 90% var: 90
  SVD rank at 99% var: 99
  Condition number (s[0]/s[k-1]): 1.00

Model 041:
  Top 5 singular values: [12.56536092 12.42352779 12.31975152 12.23004263 12.15312307]
  SVD rank at 90% var: 90
  SVD rank at 99% var: 99
  Condition number (s[0]/s[k-1]): 1.19

Model 003:
  Top 5 singular values: [7.93815652 7.91588462 7.90976774 7.88551905 7.88127244]
  SVD rank at 90% var: 90
  SVD rank at 99% var: 99
  Condition number (s[0]/s[k-1]): 1.07


=== PER-TYPE RECOVERY COMPARISON ===
Are the same neuron types hard across all models?

Model 049 - 3 hardest types: [(np.int64(0), '-2.967'), (np.int64(2), '-0.027'), (np.int64(-6), '-0.027')]
Model 011 - 3 hardest types: [(np.int64(-3), '-1.379'), (np.int64(-2), '-1.377'), (np.int64(-4), '-1.369')]
Model 041 - 3 hardest types: [(np.int64(0), '-0.983'), (np.int64(6), '-0.308'), (np.int64(2), '-0.296')]
Model 003 - 3 hardest types: [(np.int64(-6), '0.373'), (np.int64(-3), '0.374'), (np.int64(-2), '0.374')]

Cross-model type difficulty correlation:
  049 vs 011: correlation=-0.366 (n=13 types)
  049 vs 041: correlation=0.993 (n=13 types)
  049 vs 003: correlation=-1.000 (n=13 types)
  011 vs 041: correlation=-0.347 (n=13 types)
  011 vs 003: correlation=0.369 (n=13 types)
  041 vs 003: correlation=-0.994 (n=13 types)

======================================================================
SUMMARY: INSIGHTS FOR HYPOTHESIS REFINEMENT
======================================================================

1. MODEL 049 REGRESSION:
   - data_aug=25 caused R² drop from 0.634 to 0.141
   - Hypothesis: Low-rank activity (svd_99=19) + high augmentation = signal dilution
   - RECOMMENDATION: Try data_aug=15 or lr_W=1E-3 approach from Model 011

2. V_REST COLLAPSE PATTERN:
   - Models 011 (V_rest=0.004) and 041 (V_rest=0.0001) collapsed
   - Model 003 (V_rest=0.725) did NOT collapse
   - Difference: Model 003 used edge_diff=900 (vs 750 for others)
   - Hypothesis: Higher edge_diff regularizes the embedding-V_rest interaction

3. WHAT WORKED:
   - Model 003: edge_diff=900 + W_L1=3E-5 -> R²=0.972 (excellent)
   - Model 041: hidden_dim=64 + data_aug=30 -> R²=0.907 (for connectivity)
   - Model 011: lr_W=1E-3 + lr=1E-3 + W_L1=3E-5 -> R²=0.716

4. NEXT BATCH RECOMMENDATIONS:
   - Slot 0 (049): Try lr_W=1E-3+lr=1E-3 (Model 011 approach) OR data_aug=15
   - Slot 1 (011): Add edge_diff=900 to recover V_rest while keeping conn_R2
   - Slot 2 (041): Add edge_diff=900 to try to recover V_rest
   - Slot 3 (003): Minor tuning or try to push R² higher with edge_diff=1000

======================================================================
END OF ANALYSIS
======================================================================
